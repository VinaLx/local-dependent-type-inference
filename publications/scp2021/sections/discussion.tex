\section{Discussions and Future Work}

In this section we discuss some design choices and alternatives, as well
as possible future work.

\subsection{Open Terms Reduction}
\label{sec:open-term-reduction}

Usually only closed terms are considered when designing the operational semantics,
and irreducible open terms like variables are not considered to be values.
However, since in \name the reduction relation $e_1 \longrightarrow e_2$ is also
used in the unified subtyping relation, the reduced expressions can be open terms and well-typed under contexts.
\citet{full} observed this issue and included \emph{inert terms}~\citep{opencbv} as values
to capture the scenario that open terms like $x~e$
(applying variable $x$ to the argument $e$) is also irreducible, which considerably
complicates their metatheory around the operational semantics.
Fortunately, our call-by-name reduction rules do not rely on the notion of value,
which, for closed terms, represents irreducible forms.
In other words, there is no premise in our reduction rules that require
some expression to be a value or irreducible.
%Our call-by-name reduction relation only applies when a term \emph{can} reduce
%instead of when it \emph{cannot} reduce
%(there is no rule like ``if $e$ is a value, then $e_1 \longrightarrow e_2$'').
Thus, the definition of values or irreducible terms does not matter when reasoning about
type-level call-by-name reductions, and we do not have to complicate the metatheory of our system
with inert terms.
% \bruno{I modified this text a bit since it didn't seem very clear. However I'm not sure if my
% rewrite captures what you wanted to say. Please double-check carefully.}

% The type reduction in cast operators is potentially under a context that
% is not empty, so it is likely that we are performing reduction on an open term.
% Intuitively we should generalize the definition of value by introducing inert
% terms~\citep{full} to handle open term reduction.
% However since we adopt the call-by-name semantics of PITS~\citep{yang2019pure},
% there is no value check during the reduction. Whether the result of reduction
% inside a cast operator is a value or not does not matter during the reasoning of
% type safety. It is not necessary to complicate the metatheory by introducing inert terms.

\subsection{Call-by-value Semantics of Cast Operators}
\label{sec:cast-design}

An alternative design around cast operators is the
call-by-value (CBV) style~\citep{yang2019pure},
by not considering all $\castup$ terms as values, and performing cast
elimination only when the expression inside two casts is a value.
Such design requires us to have a more general definition of value, and there would
be a need for inert terms as mentioned in Section~\ref{sec:open-term-reduction}

However, a simple design with CBV-style cast semantics and inert terms
potentially leads to a system where \emph{reduction substitution}
(see section \ref{sec:typing-properties}) does not hold.
With the CBV-style reduction rules, which consist of:
\begin{mathpar}
  \inferrule*[lab=cbv-r-castdn]
    {e_1 \longrightarrow_\mathrm{cbv} e_2}
    {[[castdn e1]] \longrightarrow_\mathrm{cbv} [[castdn e2]]}~~~~~
  \inferrule*[lab=cbv-r-castup]
    {e_1 \longrightarrow_\mathrm{cbv} e_2}
    {[[castup [A] e1]] \longrightarrow_\mathrm{cbv} [[castup [A] e2]]} \\
  \inferrule*[lab=cbv-r-cast-elim]
    {\mathrm{value}~e}
    {[[castdn (castup [A] e)]] \longrightarrow_\mathrm{cbv} [[e]]}
\end{mathpar}

\noindent Assuming the notion of $\mathrm{value}$ is properly defined to
capture irreducible open terms, these rules allow reductions like:
\begin{gather*}
  \castdn \, (\castup \, [A] \, (f ~ x)) \longrightarrow_\mathrm{cbv} f ~ x
\end{gather*}
\noindent The \emph{reduction substitution} breaks if we substitute $f$ to an lambda expression:
\begin{gather*}
    [\lambda y : B. \, x / f] \, \castdn \, (\castup \, [A] \, (f ~ x)) \longrightarrow_\mathrm{cbv} \castdn \, (\castup \, [A] \, x)
\end{gather*}
The reduction rule prioritizes reducing the inner expression of two casts,
while \emph{reduction substitution} expects
$[\lambda y : B. \, x / f] \, \castdn \, (\castup \, [A] \, (f ~ x))$ to reduce to $(\lambda y : B.\, y)~x$.
% \bruno{You are missing some parenthesis here, aren't you? Around the castUp's?
%   Also, please state briefly why is the property broken. I.e. state what you were you expecting in the example
% above if the property did hold, and how what you get instead isn't the same.}

So we stick with the call-by-name style semantics around cast operators for now and
leave the discussion of other possibilities of design in future work.

\subsection{Kind Restrictions on Polymorphic Types}

Currently, we impose restrictions on the kinding of polymorphic types
($\forall x : A. B$) to require that they only have kind $\star$ but not $[[box]]$.
We believe that this has little impact on the usability
of our system since polymorphic kinds such as $\forall x : [[int]].\,\star$
do not appear frequently in practice.
It would be reasonable not to have this restriction, but this would
complicate the development of the metatheory significantly.

One of the obstacles of removing the kind restriction is that
there is a mutual dependency between the transitivity theorem and the subtyping
reasoning of polymorphic kinds. We wish to have some lemma like this:
\begin{mathpar}
    \inferrule*[]
      {[[G |- e : A]] \\ [[G |- e : *]]}
      {[[G |- * <: A : box]]}
\end{mathpar}
\noindent which depends on transitivity when the derivation of $[[G |- e : A]]$
ends with subsumption rule (\rref{s-sub}).

Note that the reverse variant of the lemma
(If $[[G |- e : A]]$ and $[[G |- e : *]]$ then $[[G |- A <: * : box]]$) is not generally
true. A counter example is $A : \star \vdash \forall a : A.\, \star \le \star$, which
does not hold if we are unable to find a well-typed instantiation of an
arbitrary type $A$, which breaks transitivity, while the derivation of the
first premise ends with \rref{s-forall-l}:
\begin{mathpar}
    \inferrule*[]
      {[[G |- [t / x] e1 <: e2 : *]] \\ [[G |- e2 <: e3 : B]] \\ [[G |- t : A]]}
      {[[G |- forall x : A. e1 <: e3 : *]]}
\end{mathpar}
We cannot apply \rref{s-forall-l} unless we can show $e_3$ is of type $[[*]]$.
One of the possiblities in this scenario is to show $[[G |- B <: * : box]]$,
which does not always hold for the reason discussed above.

Moreover, we expect complexities while reasoning about the kinding of types
after we lose the kinding uniqueness in other parts of the metatheory. Therefore
we leave the relaxation of the kinding restrictions for future work.

\subsection{Runtime Relevance of Implicit Arguments}

In our language, the implicit arguments have no computational impact at runtime
and only provide the necessary scoping for type annotations. This is
a similar design to ICC~\citep{miquel2001implicit} and
ICC*~\citep{barras2008implicit} to simplify the development of a direct
operational semantics for our language. Such a restriction can be lifted if we
prove the runtime type-safety by elaboration to a second language,
such as \emph{the Calculus of Constructions}~\citep{coc},
instead of providing the direct operational semantics.

We can elaborate implicit function types (universal types) to $\Pi$ types,
implicit abstractions to lambda expressions, and implicit instantiation to explicit
application during type checking (when we have full information about the
choice of implicit instantiations). However the elaboration on a unified subtyping
system is not an easy task. The subtyping relation cannot simply be interpreted
as a coercion between values of different types, since some of our subtyping
rules involve a relation between terms instead of types. In other words,
unified subtyping generalizes conventional subtyping relations that are defined
on types only, to a relation defined on general terms.
Therefore we leave the exploration of how elaboration can be done
on a unified subtyping system as future work.

\subsection{Algorithmic System and Challenges}

\name does not currently have an algorithmic system since we
consider a formalized algorithm for dependent type system itself a
substantial challenge. Thus, an algorithmic formulation it is left for future work.
While comparing to existing algorithmic systems
for higher-ranked polymorphic type inference for System F-like languages
~\citep{dunfield2013complete,zhao19mechanical},
we identify one of the interesting challenges to develop an algorithmic system for \name.
% the following challenges to develop an algorithmic system for \name.

% \paragraph{Unification Inside Binders}
In dependent type systems, function types ($\Pi$ types) are dependent:
the type of applications potentially depends on the values of their arguments.
Therefore the unification problem we meet is potentially inside binders and
depends on the value of the arguments. For an example in \name, consider:

\begin{equation*}
    \lambda F : [[int]] \rightarrow [[*]].\, \lambda f : F~42 \rightarrow [[int]].\, f ((\Lambda A : \star.\,\mu x : A.\, x)~42)
\end{equation*}

Here the type of $\Lambda A : \star.\,\mu x : A.\, x$ should be $\forall A : \star.\, A$.
In a non-dependent setting, one can easily conclude the instantiation for type $A$ to be
$F~42 \rightarrow [[int]]$. However in our system, the type of $A$ is a
dependent function type, with the shape of $(\Pi x : [[int]].\, F~e)$,
where expression $e$ satisfies the equation $[42/x]\,e = 42$ according to \rref{s-app}.
% Since implicit type-level computation is not allowed in our system,
% the unification problem here remains to be first order.
Here we have two choices for the instantiation of $e$, namely $x$ and $42$,
but neither choice ($\Pi x.\, F~x$ or $\Pi x.\, F~42$) for type $A$ leads to a more general
solution than choosing the other.

Notably, for a similar reason, the decidable pattern
fragment of higher-order unification~\citep{patternunification} specifically
forbids scenarios where a unification variable applies to constants.
The case shown above is similar, where the ``application'' is $A~42$
(dependent function type $A$ ``applies'' to 42) with unification variable $A$.
Nonetheless, because our system do not allow implicit type-level
computation (hence unifications remain at first-order),
the choices of $A$ are restricted to $\Pi x : [[int]].\,F~e_1$ where $[42/x]\,e_1 = 42$.
With higher-order unification we would instead
have $\Pi x : [[int]].\, e_2$ where $[42/x]\,e_2 = F~42$.

There are potentially multiple approaches to this problem. For example, we can
impose a similar restriction to the pattern unification and refuse to solve
this kind of conflicts entirely, or we can only infer non-dependent function types when
facing a unification variable, which is the choice by \citet{dh}. But which is
the better method for our system remains to be studied.

% However, we still face the
% problems with substitutions. For example, in the program above,
% the expression $e$ has two solutions, namely variable $x$
% and $42$.\bruno{So what's the problem of multiple solutions: explain that here.
%   No principal type? The two types are incomparable? If we pick one over the other then
% something may not type-check afterwards?}
%We consider coming up with a formal system a challenging problem to
%resolve the general issues that this example implies.

\subsection{The Issues of Strengthening}
\label{sec:habitability}

The current lack of proof of \emph{strengthening} property leads to non-trivial
changes during the generalization of polymorphic subtyping relation as
described in Section \ref{sec:strengthening}. It would be nice to be able to
have strengthening so the system could be simplified. However the issues are
quite tricky.

\paragraph{Type Inhabitation}
As we mentioned earlier, one of the issues is centered around not being able to find an
well-typed instantiation for an arbitrary type in general. Nevertheless, in the presence of
seemingly unused variables it may be possible to find well-typed instantiations,
which is a key reason for strenghtning not holding in general. For example:

\begin{equation*}
    A : [[*]], \rulehl{a : A} \vdash [[(bind x : A. lambda y : int. y)]]~42 : [[int]]
\end{equation*}

Here to conclude that $[[bind x : A. lambda y : int. y]]$ has type $[[int]] \rightarrow [[int]]$,
we want to derive $\forall x : A.\, [[int]] \rightarrow [[int]] \le [[int]] \rightarrow [[int]]$ by
using \rref{s-forall-l}. That would require a well-typed instantiation
for the abstract type $A$, and that is where the variable $a$ in the context
comes to rescue, although not being used anywhere in the original typing relation.
Thus, unlike other calculi where it is possible to drop unused variables in the context
and still have a valid typing statement, in \name this is not always possible. In the example
above dropping $\rulehl{a : A}$ from the context results in an typing statement that does not hold
(unless we can find another inhabitant for the type $A$ somehow).
In other words, a conventional strenghtning property does not hold.

However, since \name supports fixpoints, all monotypes in our system
are easily inhabited with diverging programs as inhabitants (recall that, due
to the issue discussed in Section~\ref{sec:reverse-subst}, our fixpoints only support monotypes).
For instance, we do not need the variable $a$ in the context in the example above,
we can just find the instantiation $\mu x : A. x$ to satisfy \rref{s-forall-l}, if $A$ is a
monotype.
Moreover, it is \emph{likely} that any polytype can have an inhabitant with the help
of monotype fixpoints, for example, type $\forall A : [[*]],\, A \rightarrow B$ with $B$
being an abstract type, has an inhabitant $\Lambda A : [[*]].\,[[lambda x : A. mu y : B. y]]$.

Nevertheless, since polymorphic types in our system also serve as ``implicit function types'',
it seems a weird choice to infer diverging programs as their implicit arguments.
Inferring infinite loops is not a big deal for the time being,
because we guarantee the runtime irrelevance
of all the implicit arguments. But this design will not be reasonable if we are
going to relax the restriction of runtime irrelevance of implicit parameters in the future.
Furthermore, it is also reasonable to consider similar language designs without fixpoints
(for instance if our goals are to develop theorem provers or strongly normalizing languages).
In such scenarios the approach of finding inhabitants by creating non-terminating terms
would not be possible. Thus such an approach would not be very generalizable.

\paragraph{Occurences of variables that matter}
Another issue for the strengthening is that even if we have the issue of
inhabitability covered, it is tricky to guarantee that a variable unused in the
final subtyping conclusion, does not matter for the whole derivation.
For example in \rref{s-app}, where type $A$ in the premises does not
occur at all in the conclusion, we cannot guarantee that a variable that
does not occur in the conclusion, does not occur in type $A$. We can construct
the following example:

\begin{mathpar}
    \inferrule*[Right=s-app]
      {  T : [[*]] \vdash 42 : \forall y : T \rightarrow T.\, [[int]]
      \\ T : [[*]] \vdash [[lambda x : int. x]] : (\forall y : T \rightarrow T.\, [[int]]) \rightarrow [[int]] }
      {T : [[*]] \vdash ([[lambda x : int. x]])~42 : [[int]]}
\end{mathpar}

\noindent Here the variable $T$ does not occur in the conclusion
(other than in the context, of course), but occurs in
the premises. The interesting part is that although it occurs in the premises, without
it, the conclusion holds with a different derivation tree (by directly deriving $\vdash 42 : [[int]]$).
For this example, although the strengthening property holds, we do not currently
know how to determine whether a variable really \emph{matters} for a derivation
in general.

So for the two issues we discussed above, we decide to live with the lack of
strengthening property in our system for now, at the cost of a slightly more
complicated system with additional kinding premises in \rref{s-forall-r}
and the addition of \rref{s-forall}.

% In polymorphic subtyping, we do not need a ``real'' instantiation to conclude
% that a subtyping relation holds. For example, in polymorphic subtyping:
% \begin{equation*}
%     \forall A.\, (A \rightarrow A) \rightarrow [[int]] \le (\forall A.\, A \rightarrow A) \rightarrow [[int]]
% \end{equation*}
% \noindent holds by first applying rule $\forallL$ with a dummy instantiation,
% say $[[int]]$, and then showing $\forall A.\, A \rightarrow A \le [[int]] \rightarrow [[int]]$.
% This clearly holds by applying rule $\forallL$ again. However such dummy instantiations
% pose extra difficulties in \name:
% \begin{equation*}
%     \forall A : T.\, (A \rightarrow A) \rightarrow [[int]] \le (\forall A : T.\, A \rightarrow A) \rightarrow [[int]]
% \end{equation*}
% We cannot apply \rref{s-forall-l} until we find a valid instantiation for type $A$,
% therefore we encounter an \emph{inhabitation problem} for \name. This problem is
% undecidable for System F~\citep{dudenhefner2019simpler}. We do not expect it to be
% decidable in a more complicated system with strong normalization.
% Since we support general recursion in our language with a mono-expression
% restriction we expect that all types are
% inhabited. However, we currently do not have the proof backing the claim that
% this is the case.
